import os
import warnings
import tempfile
import subprocess
from pathlib import Path

from faster_whisper import WhisperModel
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

LOCAL_MODEL_PATH = os.path.join(root_dir, 'models', "faster-whisper-large-v3")

class WhisperModelSingleton:
    _instance = None
    _model = None

    def __new__(cls, model_size="large-v3", device="cuda"):
        if cls._instance is None:
            cls._instance = super(WhisperModelSingleton, cls).__new__(cls)

            warnings.filterwarnings("ignore", category=FutureWarning)
            warnings.filterwarnings("ignore", category=UserWarning)
            # å¦‚æœæœ¬åœ°å­˜åœ¨æ¨¡å‹ï¼Œåˆ™ä»æœ¬åœ°åŠ è½½
            if os.path.exists(LOCAL_MODEL_PATH):
                print(f"ğŸ“¦ æ­£åœ¨ä»æœ¬åœ°åŠ è½½æ¨¡å‹: {LOCAL_MODEL_PATH}")
                cls._model = WhisperModel(
                    model_size_or_path=LOCAL_MODEL_PATH,
                    device=device,
                )
            else:
                print(f"ğŸŒ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œæ­£åœ¨ä»è¿œç¨‹ä¸‹è½½: {model_size}")
                cls._model = WhisperModel(
                    model_size_or_path=model_size,
                    device=device,
                )
        return cls._instance

    def transcribe(self, audio_path, **kwargs):
        """
        è°ƒç”¨ whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
        :param audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :param kwargs: å…¶ä»– transcribe å‚æ•°
        :return: segments, info
        """
        segments, info = self._model.transcribe(audio_path, **kwargs)
        segments = list(segments)
        return segments, info

    def transcribe_video(self, video_path, **kwargs):
        """
        ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘å¹¶è¿›è¡Œè½¬å½•
        :param video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        :param kwargs: å…¶ä»– transcribe å‚æ•°
        :return: segments, info
        """
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºå­˜å‚¨æå–çš„éŸ³é¢‘
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_audio:
            tmp_audio_path = tmp_audio.name

        try:
            # ä»è§†é¢‘ä¸­æå–éŸ³é¢‘
            self._extract_audio_from_video(video_path, tmp_audio_path)
            
            # è½¬å½•éŸ³é¢‘
            segments, info = self.transcribe(tmp_audio_path, **kwargs)
            
            return segments, info
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(tmp_audio_path):
                os.remove(tmp_audio_path)

    def _extract_audio_from_video(self, video_path, output_path):
        """
        ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘
        :param video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        :param output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        print(f"æ­£åœ¨ä»è§†é¢‘æå–éŸ³é¢‘: {video_path}")
        
        # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-vn',  # ç¦ç”¨è§†é¢‘
            '-ac', '1',  # å•å£°é“
            '-ar', '16000',  # é‡‡æ ·ç‡
            '-acodec', 'pcm_s16le',  # éŸ³é¢‘ç¼–è§£ç å™¨
            '-f', 'wav',  # è¾“å‡ºæ ¼å¼
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            output_path
        ]
        
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            print(f"éŸ³é¢‘æå–å®Œæˆ: {output_path}")
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"éŸ³é¢‘æå–å¤±è´¥: {e.stderr.decode()}")

    def generate_srt(self, segments, output_path):
        """
        å°†è½¬å½•ç»“æœç”ŸæˆSRTå­—å¹•æ–‡ä»¶
        :param segments: è½¬å½•çš„ç‰‡æ®µåˆ—è¡¨
        :param output_path: SRTæ–‡ä»¶è¾“å‡ºè·¯å¾„
        """
        with open(output_path, 'w', encoding='utf-8') as srt_file:
            for i, segment in enumerate(segments, 1):
                # æ ¼å¼åŒ–å¼€å§‹æ—¶é—´
                start_time = self._format_time(segment.start)
                # æ ¼å¼åŒ–ç»“æŸæ—¶é—´
                end_time = self._format_time(segment.end)
                
                # å†™å…¥SRTæ ¼å¼å†…å®¹
                srt_file.write(f"{i}\n")
                srt_file.write(f"{start_time} --> {end_time}\n")
                srt_file.write(f"{segment.text.strip()}\n\n")
                
        print(f"SRTå­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")

    def _format_time(self, seconds):
        """
        å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼ (HH:MM:SS,mmm)
        :param seconds: ç§’æ•°
        :return: æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

    def transcribe_to_srt(self, file_path, output_path, file_type='auto', **kwargs):
        """
        è½¬å½•éŸ³é¢‘/è§†é¢‘æ–‡ä»¶å¹¶ç”ŸæˆSRTå­—å¹•æ–‡ä»¶
        :param file_path: éŸ³é¢‘/è§†é¢‘æ–‡ä»¶è·¯å¾„
        :param output_path: SRTæ–‡ä»¶è¾“å‡ºè·¯å¾„
        :param file_type: æ–‡ä»¶ç±»å‹ ('audio', 'video' æˆ– 'auto')
        :param kwargs: å…¶ä»– transcribe å‚æ•°
        """
        # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
        audio_extensions = ['.wav', '.mp3', '.flac', '.aac', '.m4a']
        # æ”¯æŒçš„è§†é¢‘æ ¼å¼
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv']
        
        if file_type == 'auto':
            file_ext = Path(file_path).suffix.lower()
            if file_ext in audio_extensions:
                file_type = 'audio'
            elif file_ext in video_extensions:
                file_type = 'video'
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        
        # è½¬å½•æ–‡ä»¶
        if file_type == 'audio':
            segments, info = self.transcribe(file_path, **kwargs)
        elif file_type == 'video':
            segments, info = self.transcribe_video(file_path, **kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
        
        # ç”ŸæˆSRTæ–‡ä»¶
        self.generate_srt(segments, output_path)
        return segments, info


if __name__ == "__main__":
    model = WhisperModelSingleton()
    # segments, info = model.transcribe_video("test.mp4")
    # print(segments)
    # print(info)
    
    # ç¤ºä¾‹ï¼šè½¬å½•è§†é¢‘å¹¶ç”ŸæˆSRTå­—å¹•æ–‡ä»¶
    file_path= r"D:\PycharmProjects\VideoCube\test\assets\xhs_live.mp4"
    segments, info = model.transcribe_to_srt(file_path, "output.srt")
    print(f"è½¬å½•å®Œæˆï¼Œç”ŸæˆSRTæ–‡ä»¶: output.srt")
    print(f"æ£€æµ‹åˆ°è¯­è¨€: {info.language}")
    print(f"è¯­è¨€æ¦‚ç‡: {info.language_probability}")